"""
PROJET ML : PR√âDICTION DE SURVIE DU TITANIC
√âtape 2 : √âvaluation d'une s√©lection de mod√®les de Classification
"""

import pandas as pd
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
import numpy as np
import warnings
import os

# Ignorer les avertissements pour une sortie plus propre
warnings.filterwarnings('ignore')

# Configuration
OUTPUT_DIR = 'processed_data'
RANDOM_SEED = 42

# ==============================================================================
# 1. CHARGEMENT DES DONN√âES PR√âTRAIT√âES
# ==============================================================================

def load_data():
    """
    Charge les jeux de donn√©es pr√©trait√©s depuis le dossier 'processed_data'.
    """
    X_train_path = os.path.join(OUTPUT_DIR, 'X_train_processed.csv')
    y_train_path = os.path.join(OUTPUT_DIR, 'y_train_processed.csv') # Correction du nom de fichier pour la cible
    X_test_path = os.path.join(OUTPUT_DIR, 'X_test_processed.csv')
    
    X_train, y_train, X_test = pd.DataFrame(), pd.Series(dtype='int'), pd.DataFrame()
    
    if not (os.path.exists(X_train_path) and os.path.exists(y_train_path) and os.path.exists(X_test_path)):
        print(f"ATTENTION: Les fichiers de donn√©es pr√©trait√©es sont introuvables dans le dossier '{OUTPUT_DIR}'.")
        print("Le script va cr√©er des donn√©es SIMUL√âES pour la d√©monstration des mod√®les.")
        
        # Cr√©er des donn√©es simul√©es bas√©es sur les shapes et la structure attendues
        n_train = 891
        n_test = 418
        n_features = 29
        
        X_train = pd.DataFrame(np.random.rand(n_train, n_features), 
                                columns=[f'feature_{i}' for i in range(n_features)])
        y_train = pd.Series(np.random.randint(0, 2, n_train))
        X_test = pd.DataFrame(np.random.rand(n_test, n_features), 
                              columns=[f'feature_{i}' for i in range(n_features)])
        
        # S'assurer que les colonnes sont identiques
        X_test = X_test.reindex(columns=X_train.columns, fill_value=0)
        
    else:
        try:
            # Charger les donn√©es r√©elles
            X_train = pd.read_csv(X_train_path)
            # IMPORTANT: Le script 01_preprocessing a sauv√© y_train dans un fichier avec une colonne 'Survived'
            y_train = pd.read_csv(y_train_path)['Survived'] 
            X_test = pd.read_csv(X_test_path)
            
            # Revenir √† la simulation si le fichier y_train est vide apr√®s lecture
            if X_train.empty or y_train.empty or X_test.empty:
                 raise ValueError("Les DataFrames charg√©s sont vides.")

        except Exception as e:
            print(f"Erreur lors du chargement des donn√©es r√©elles: {e}")
            print("Retour √† la SIMULATION de donn√©es pour l'ex√©cution.")
            
            # Cr√©er des donn√©es simul√©es en cas d'√©chec de lecture
            n_train = 891
            n_test = 418
            n_features = 29
            X_train = pd.DataFrame(np.random.rand(n_train, n_features), columns=[f'feature_{i}' for i in range(n_features)])
            y_train = pd.Series(np.random.randint(0, 2, n_train))
            X_test = pd.DataFrame(np.random.rand(n_test, n_features), columns=[f'feature_{i}' for i in range(n_features)])
            X_test = X_test.reindex(columns=X_train.columns, fill_value=0)


    print(f"\n‚úÖ Donn√©es charg√©es et pr√™tes pour l'entra√Ænement.")
    print(f"Shape X_train: {X_train.shape}")
    print(f"Shape y_train: {y_train.shape}")
    print(f"Shape X_test: {X_test.shape}")
    
    return X_train, y_train, X_test


# ==============================================================================
# 2. √âVALUATION DES MOD√àLES
# ==============================================================================

def evaluate_models(X_train, y_train):
    """
    Initialise et √©value une s√©lection de mod√®les de classification
    en utilisant la validation crois√©e stratifi√©e.
    """
    if X_train.empty or y_train.empty:
        print("\n‚ùå Impossible d'√©valuer les mod√®les: Les donn√©es d'entra√Ænement sont vides.")
        return None

    print("\n==================================================")
    print("üß† √âVALUATION DES MOD√àLES AVEC VALIDATION CROIS√âE")
    print("==================================================")

    # D√©finition des mod√®les √† tester
    classifiers = {
        "R√©gression Logistique": LogisticRegression(random_state=RANDOM_SEED, max_iter=200),
        "K-plus Proches Voisins": KNeighborsClassifier(n_neighbors=5),
        # SVC avec probabilit√© activ√©e pour pouvoir comparer les probabilit√©s si besoin
        "Machine √† Vecteurs de Support": SVC(random_state=RANDOM_SEED, probability=True), 
        "Arbre de D√©cision": DecisionTreeClassifier(random_state=RANDOM_SEED),
        # Random Forest est souvent un bon point de d√©part
        "For√™t Al√©atoire": RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=100),
        # Gradient Boosting est souvent tr√®s performant
        "Gradient Boosting": GradientBoostingClassifier(random_state=RANDOM_SEED),
        "Na√Øf Bayes Gaussien": GaussianNB()
    }

    # Configuration de la validation crois√©e
    cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)
    
    results = {}

    for name, model in classifiers.items():
        try:
            # Calculer les scores de validation crois√©e
            # Utiliser n_jobs=-1 pour parall√©liser l'entra√Ænement et acc√©l√©rer le processus
            scores = cross_val_score(model, X_train, y_train, cv=cv_strategy, scoring='accuracy', n_jobs=-1) 
            
            # Enregistrer la moyenne et l'√©cart-type des scores
            results[name] = {
                'Moyenne Pr√©cision (CV)': scores.mean(),
                '√âcart-type (CV)': scores.std()
            }
            
            # Affichage des r√©sultats interm√©diaires
            print(f" ¬†{name:<30}: {scores.mean():.4f} (+/- {scores.std():.4f})")
            
        except Exception as e:
            print(f" ¬†{name:<30}: √âCHEC de l'entra√Ænement. Erreur: {e}")
            results[name] = {'Moyenne Pr√©cision (CV)': 0.0, '√âcart-type (CV)': 0.0}

    # Trier et afficher le meilleur mod√®le
    best_model_name = max(results, key=lambda k: results[k]['Moyenne Pr√©cision (CV)'])
    best_score = results[best_model_name]['Moyenne Pr√©cision (CV)']

    print("\n==================================================")
    print(f"üèÜ MEILLEUR MOD√àLE (Pr√©cision Moyenne): {best_model_name}")
    print(f" ¬† Score de Pr√©cision Moyen: {best_score:.4f}")
    print("==================================================")

    return classifiers[best_model_name]

# ==============================================================================
# 3. ENTRA√éNEMENT FINAL ET PR√âDICTION
# ==============================================================================

def final_prediction(best_model, X_train, y_train, X_test):
    """
    Entra√Æne le meilleur mod√®le sur l'int√©gralit√© du jeu d'entra√Ænement
    et g√©n√®re les pr√©dictions pour le jeu de test.
    """
    if X_train.empty or y_train.empty or X_test.empty:
        print("\n‚ùå Impossible de faire les pr√©dictions finales: Jeux de donn√©es incomplets.")
        return

    print("\n==================================================")
    print(f"üöÄ ENTRA√éNEMENT FINAL et PR√âDICTION")
    print("==================================================")
    
    # 1. Entra√Ænement final
    print(f"Entra√Ænement du mod√®le {best_model.__class__.__name__} sur toutes les donn√©es d'entra√Ænement...")
    best_model.fit(X_train, y_train)
    
    # 2. Pr√©dictions
    print("G√©n√©ration des pr√©dictions pour le jeu de test...")
    predictions = best_model.predict(X_test)
    
    # 3. Cr√©ation du fichier de soumission (format Kaggle)
    
    # Tenter de charger les PassengerId du fichier de test original
    try:
        test_raw = pd.read_csv('data/test.csv')
        passenger_ids = test_raw['PassengerId']
        
    except FileNotFoundError:
        print("\n‚ö†Ô∏è Impossible de charger 'data/test.csv' pour r√©cup√©rer les PassengerId. Utilisation d'IDs simul√©s.")
        passenger_ids = range(892, 892 + len(predictions))
    
    submission_df = pd.DataFrame({
        'PassengerId': passenger_ids,
        'Survived': predictions.astype(int)
    })
    
    submission_file = 'submission_titanic.csv'
    submission_df.to_csv(submission_file, index=False)
    
    print(f"\n‚úÖ PR√âDICTIONS TERMIN√âES et Fichier de soumission cr√©√©: {submission_file}")
    print(f" ¬† Premi√®res 5 pr√©dictions: {predictions[:5]}")
    print(f" ¬† Shape du fichier de soumission: {submission_df.shape}")
    print("==================================================")


if __name__ == '__main__':
    # √âtape 1: Charger les donn√©es
    X_train, y_train, X_test = load_data()

    # √âtape 2: √âvaluer les mod√®les
    if not X_train.empty:
        best_model = evaluate_models(X_train, y_train)

        # √âtape 3: Entra√Ænement final et soumission
        final_prediction(best_model, X_train, y_train, X_test)

    print("\nFin du script 02_model_evaluation.py")