# ğŸš¢ Projet Titanic : PrÃ©diction de Survie

**Auteur :** Ettaoussi Soukaina

---

## ğŸ“‹ Description du Projet

Ce projet vise Ã  prÃ©dire la survie des passagers du Titanic en utilisant des techniques de Machine Learning. Il s'agit d'un projet classique de classification binaire basÃ© sur le cÃ©lÃ¨bre dataset Kaggle "Titanic - Machine Learning from Disaster".

L'objectif est d'analyser les caractÃ©ristiques des passagers (Ã¢ge, sexe, classe, etc.) pour dÃ©terminer les facteurs qui ont influencÃ© leur survie lors du naufrage du Titanic en 1912.

---

## ğŸ¯ Objectifs

- Effectuer une **analyse exploratoire des donnÃ©es (EDA)** complÃ¨te
- CrÃ©er de nouvelles **features** pertinentes (feature engineering)
- GÃ©rer les **valeurs manquantes** de maniÃ¨re intelligente
- Ã‰valuer plusieurs **modÃ¨les de classification**
- SÃ©lectionner le **meilleur modÃ¨le** et gÃ©nÃ©rer des prÃ©dictions

---

## ğŸ“‚ Structure du Projet

```
PROJET TITANIC/
â”‚
â”œâ”€â”€ data/                          # DonnÃ©es brutes
â”‚   â”œâ”€â”€ train.csv                  # Jeu d'entraÃ®nement
â”‚   â”œâ”€â”€ test.csv                   # Jeu de test
â”‚   â””â”€â”€ gender_submission.csv      # Exemple de soumission
â”‚
â”œâ”€â”€ processed_data/                # DonnÃ©es prÃ©traitÃ©es
â”‚   â”œâ”€â”€ X_train_processed.csv      # Features d'entraÃ®nement
â”‚   â”œâ”€â”€ y_train_processed.csv      # Cible d'entraÃ®nement
â”‚   â””â”€â”€ X_test_processed.csv       # Features de test
â”‚
â”œâ”€â”€ Screenshots/                   # Captures d'Ã©cran des rÃ©sultats
â”‚   â”œâ”€â”€ titanic_preprocessing.png
â”‚   â”œâ”€â”€ evaluate_models_by_cross_validation.png
â”‚   â”œâ”€â”€ train_final_and_prediction.png
â”‚   â”œâ”€â”€ MatrixCorrelation.png
â”‚   â””â”€â”€ visualisation.png
â”‚
â”œâ”€â”€ 01_eda_preprocessing.py        # Script de prÃ©traitement
â”œâ”€â”€ 02_modeling.py                 # Script de modÃ©lisation
â”œâ”€â”€ submission_titanic.csv         # Fichier de soumission Kaggle
â””â”€â”€ Readme.md                      # Documentation du projet
```

---

## ğŸ”§ Technologies UtilisÃ©es

### Langages et BibliothÃ¨ques
- **Python 3.x**
- **pandas** : Manipulation des donnÃ©es
- **numpy** : Calculs numÃ©riques
- **matplotlib & seaborn** : Visualisations
- **scikit-learn** : ModÃ¨les de Machine Learning

### ModÃ¨les Ã‰valuÃ©s
- RÃ©gression Logistique
- K-plus Proches Voisins (KNN)
- Machine Ã  Vecteurs de Support (SVM)
- Arbre de DÃ©cision
- ForÃªt AlÃ©atoire (Random Forest)
- **Gradient Boosting** â­ (Meilleur modÃ¨le)
- NaÃ¯f Bayes Gaussien

---

## ğŸ“Š Pipeline de Preprocessing

![Titanic Preprocessing](Screenshots/titanic_preprocessing.png)

### 1. **Analyse Exploratoire (EDA)**
- Statistiques descriptives
- Analyse des valeurs manquantes
- Visualisation des distributions
- Matrice de corrÃ©lation

#### Visualisations de Survie
![Analyse de Survie](visualisation.png)

#### Matrice de CorrÃ©lation
![Matrice de CorrÃ©lation](MatrixCorrelation.png)

### 2. **Feature Engineering**
CrÃ©ation de nouvelles features :
- **Title** : Extraction du titre depuis le nom (Mr, Mrs, Miss, Master, Rare)
- **FamilySize** : Taille de la famille (SibSp + Parch + 1)
- **IsAlone** : Indicateur de passager seul
- **AgeGroup** : CatÃ©gories d'Ã¢ge (Enfant, Adolescent, Adulte, Senior, Ã‚gÃ©)
- **FareGroup** : CatÃ©gories de prix (Bas, Moyen, Ã‰levÃ©, TrÃ¨s Ã©levÃ©)
- **Deck** : Pont du bateau (premiÃ¨re lettre de Cabin)

### 3. **Gestion des Valeurs Manquantes**
- **Age** : Imputation par la mÃ©diane selon le titre et la classe
- **Embarked** : Imputation par le mode
- **Fare** : Imputation par la mÃ©diane
- **Cabin** : CrÃ©ation d'une catÃ©gorie "Unknown"

### 4. **Encodage**
- **Label Encoding** pour la variable binaire (Sex)
- **One-Hot Encoding** pour les variables catÃ©gorielles (Embarked, Title, Deck, AgeGroup, FareGroup)

---

## ğŸ§  RÃ©sultats des ModÃ¨les

### Scores de Validation CroisÃ©e (10-Fold)

![Ã‰valuation des ModÃ¨les](Screenshots/evaluate_models_by_cross_validation.png)

| ModÃ¨le                           | PrÃ©cision Moyenne | Ã‰cart-type |
|----------------------------------|-------------------|------------|
| RÃ©gression Logistique            | 0.8248            | Â±0.0336    |
| K-plus Proches Voisins           | 0.7161            | Â±0.0328    |
| Machine Ã  Vecteurs de Support    | 0.6812            | Â±0.0261    |
| Arbre de DÃ©cision                | 0.7900            | Â±0.0512    |
| ForÃªt AlÃ©atoire                  | 0.8170            | Â±0.0300    |
| **Gradient Boosting** ğŸ†         | **0.8361**        | **Â±0.0234** |
| NaÃ¯f Bayes Gaussien              | 0.7654            | Â±0.0450    |

### ğŸ† Meilleur ModÃ¨le
**Gradient Boosting Classifier** avec une prÃ©cision moyenne de **83.61%**

### EntraÃ®nement Final et PrÃ©dictions

![PrÃ©dictions Finales](Screenshots/train_final_and_prediction.png)

---

## ğŸš€ Utilisation

### Installation des dÃ©pendances
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### ExÃ©cution du projet

#### Ã‰tape 1 : Preprocessing
```bash
python 01_eda_preprocessing.py
```
Ce script gÃ©nÃ¨re :
- Les fichiers CSV prÃ©traitÃ©s dans `processed_data/`
- Des visualisations pour l'EDA

#### Ã‰tape 2 : ModÃ©lisation
```bash
python 02_modeling.py
```
Ce script :
- Ã‰value tous les modÃ¨les avec validation croisÃ©e
- EntraÃ®ne le meilleur modÃ¨le
- GÃ©nÃ¨re le fichier de soumission `submission_titanic.csv`

---

## ğŸ“ˆ Insights ClÃ©s

### Facteurs de Survie IdentifiÃ©s
1. **Sexe** : Les femmes avaient un taux de survie beaucoup plus Ã©levÃ©
2. **Classe** : Les passagers de 1Ã¨re classe avaient plus de chances de survie
3. **Ã‚ge** : Les enfants avaient un taux de survie supÃ©rieur
4. **Taille de la famille** : Les petites familles (2-4 personnes) s'en sortaient mieux
5. **Prix du billet** : CorrÃ©lation positive avec la survie

### CorrÃ©lations Principales
- **Sex** et **Survived** : Forte corrÃ©lation nÃ©gative (encodÃ©e : 0=female, 1=male)
- **Pclass** et **Survived** : CorrÃ©lation nÃ©gative (classe infÃ©rieure = moins de survie)
- **Fare** et **Survived** : CorrÃ©lation positive

---

## ğŸ“ Conclusions

Ce projet dÃ©montre l'importance d'un preprocessing rigoureux et d'un feature engineering crÃ©atif. Le modÃ¨le **Gradient Boosting** s'est rÃ©vÃ©lÃ© le plus performant avec une prÃ©cision de **83.61%**, surpassant les modÃ¨les plus simples comme la rÃ©gression logistique.

Les rÃ©sultats confirment les facteurs socio-Ã©conomiques et dÃ©mographiques qui ont influencÃ© la survie lors de la tragÃ©die du Titanic : la rÃ¨gle "les femmes et les enfants d'abord" Ã©tait clairement appliquÃ©e, et la classe sociale jouait un rÃ´le dÃ©terminant.

---

## ğŸ“§ Contact

**Ettaoussi Soukaina**

Pour toute question ou suggestion concernant ce projet, n'hÃ©sitez pas Ã  me contacter.

---

## ğŸ“œ Licence

Ce projet est rÃ©alisÃ© dans un cadre Ã©ducatif et utilise le dataset public Kaggle Titanic.

---

*Projet rÃ©alisÃ© avec passion pour l'apprentissage automatique et l'analyse de donnÃ©es* ğŸš¢ğŸ’™